# GPU-Optimized Dockerfile for BERT Training
# Uses NVIDIA CUDA base image for GPU acceleration

FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04 as base

# Set working directory
WORKDIR /app

# Install Python and system dependencies
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    build-essential \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*

# Create symbolic link for python
RUN ln -s /usr/bin/python3.10 /usr/bin/python

# Upgrade pip
RUN pip install --no-cache-dir --upgrade pip

# Copy and install requirements
COPY requirements.txt .

# Install PyTorch with CUDA support
RUN pip install --no-cache-dir \
    torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 \
    --index-url https://download.pytorch.org/whl/cu118

# Install other requirements
RUN pip install --no-cache-dir -r requirements.txt

# Stage 2: Training environment
FROM base as training

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV TRANSFORMERS_CACHE=/app/cache
ENV HF_HOME=/app/cache
ENV CUDA_VISIBLE_DEVICES=0

# Create directory structure
RUN mkdir -p data/raw \
    data/processed \
    src/data \
    src/models \
    src/utils \
    models/checkpoints \
    mlruns \
    logs \
    cache

# Copy source code
COPY src/ ./src/
COPY configs/ ./configs/

# Create __init__.py files
RUN touch src/__init__.py \
    src/data/__init__.py \
    src/models/__init__.py \
    src/utils/__init__.py

# Enhanced entrypoint with GPU detection
RUN echo '#!/bin/bash\n\
set -e\n\
\n\
echo "========================================"\n\
echo "BERT Sentiment Analysis (GPU-Accelerated)"\n\
echo "========================================"\n\
echo ""\n\
\n\
# Check GPU availability\n\
echo "ðŸ” Checking GPU availability..."\n\
python -c "import torch; print(f\"CUDA available: {torch.cuda.is_available()}\"); print(f\"GPU count: {torch.cuda.device_count()}\"); print(f\"GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}\")"\n\
echo ""\n\
\n\
# Step 1: Data Preparation\n\
echo "ðŸ“¥ Step 1/3: Downloading and preprocessing data..."\n\
python src/data/prepare_data.py\n\
echo "âœ… Data preparation complete!"\n\
echo ""\n\
\n\
# Step 2: Model Training\n\
echo "ðŸš€ Step 2/3: Starting GPU-accelerated training..."\n\
python src/models/train.py\n\
echo "âœ… Model training complete!"\n\
echo ""\n\
\n\
# Step 3: Summary\n\
echo "ðŸ“Š Step 3/3: Training Summary"\n\
echo "========================================"\n\
if [ -f "models/checkpoints/best_model.pth" ]; then\n\
    echo "âœ… Model saved: models/checkpoints/best_model.pth"\n\
    MODEL_SIZE=$(du -h models/checkpoints/best_model.pth | cut -f1)\n\
    echo "ðŸ“¦ Model size: $MODEL_SIZE"\n\
fi\n\
\n\
if [ -d "mlruns" ]; then\n\
    RUN_COUNT=$(find mlruns -type d -name "*" -type d | wc -l)\n\
    echo "ðŸ“ˆ MLflow tracking initialized"\n\
fi\n\
\n\
echo ""\n\
echo "========================================"\n\
echo "ðŸŽ‰ GPU Training completed successfully!"\n\
echo "========================================"\n\
' > /app/run_pipeline.sh && chmod +x /app/run_pipeline.sh

ENTRYPOINT ["/app/run_pipeline.sh"]
CMD []

EXPOSE 5000

VOLUME ["/app/data", "/app/models", "/app/mlruns", "/app/logs"]